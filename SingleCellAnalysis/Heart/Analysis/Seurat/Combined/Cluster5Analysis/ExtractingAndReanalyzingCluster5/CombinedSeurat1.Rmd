---
title: "Clustering of combined young and aged cardiac endothelial cells "
output: html_document
---
# I have merged the gene matrices of young and aged brain endothelial cells
# Load the libraries and the data
```{r cars}
setwd("/Volumes/Uchenna_MacDesk/UchennaDesktop/Desktop/BarnesLab/SingleCellRNASeq/YoungCardiacOldCardiacEndothelialCells/Project_CEL171114AB_Data/Combined_Cardiac")
library(Seurat)
library(cowplot)
# read in the expression matrix
Combined = read.csv("Combined.csv",row.names=1)
# Sanity check
dim(Combined)
Combined[1:3,1:3]
# The csv files contains Cells as columns and Genes (features) in rows
# Size of data set is 4348 Cells and 27998 Genes
# Lets save the cell names of this dataset to be used to create the annotation file
Names = colnames(Combined)
# This has genes as rows (~27k) and cells as columns (4348)
# I created an annotation that has 1 column, CellType and 4348 rows. Each row matches each column in the
# Combined data and describes each of these cells as either Young nor Old
# Read in the annotation file
AnnotationFile = read.csv('CellAnnotation.csv',row.names=1)
# Sanity check
dim(AnnotationFile)
head(AnnotationFile)
tail(AnnotationFile)
# The annotation file has rownames as sequential indexes. 
# Reformat the annotation file to have the cell names from the combined as rownames
# Add the Names from Combined data as another column in the annotation file
AnnotationFile1 = cbind(AnnotationFile,'CellNames'= Names)
# Sanity check
head(AnnotationFile1)
# Now make this CellNames column as the row names
rownames(AnnotationFile1) = AnnotationFile1$CellNames
# Sanity check
head(AnnotationFile1)
# Now drop the redundant CellNames column
library(dplyr)
AnnotationFile2 = AnnotationFile1 %>% select(-CellNames)
# Sanity check
head(AnnotationFile2)
```

# Seurat Analysis
```{r}
# First make the expression data as a sparse data frame to speed up computation. 
# Our combined data is not numeric, so convert the data frame to numeric
Combined1 = data.matrix(Combined)
# Then convert to a sparse matrix
expression.data <- Matrix(Combined1, sparse = T)
# Sanity check
expression.data[1:3,1:3]

New <- CreateSeuratObject(raw.data = expression.data, min.cells = 3, min.genes = 200, 
    project = "10X_old")

mito.genes <- grep(pattern = "^MT-", x = rownames(x = New@data), value = TRUE)
percent.mito <- Matrix::colSums(New@raw.data[mito.genes, ])/Matrix::colSums(New@raw.data)
# Add percent.mito to the metadata
New <- AddMetaData(object = New, metadata = percent.mito, col.name = "percent.mito")
# Also add the cell annotation as part of the metadata
New1 = AddMetaData(object=New,metadata = AnnotationFile2)
# This threw up a warning. Understand that warning. The plot is also kinda different from the plot from the tutorial;
# The warning is that all cells have the same value of feature
VlnPlot(object = New1, features.plot = c("nGene", "nUMI", "percent.mito"), nCol = 3)

# We filter out cells that have unique gene counts over 2,500 or less than
# 200 Note that low.thresholds and high.thresholds are used to define a
# 'gate' -Inf and Inf should be used if you don't want a lower or upper
# threshold.
New <- FilterCells(object = New1, subset.names = c("nGene", "percent.mito"), 
    low.thresholds = c(200, -Inf), high.thresholds = c(2500, 0.05))

# Normalizing the data
# After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.

New <- NormalizeData(object = New, normalization.method = "LogNormalize", 
    scale.factor = 10000)

# Detection of variable genes across the single cells
# Seurat calculates highly variable genes and focuses on these for downstream analysis. FindVariableGenes calculates the average expression and dispersion for each gene, places these genes into bins, and then calculates a z-score for dispersion within each bin. This helps control for the relationship between variability and average expression. This function is unchanged from (Macosko et al.), but new methods for variable gene expression identification are coming soon. We suggest that users set these parameters to mark visual outliers on the dispersion plot, but the exact parameter settings may vary based on the data type, heterogeneity in the sample, and normalization strategy. The parameters here identify ~2,000 variable genes, and represent typical parameter settings for UMI data that is normalized to a total of 1e4 molecules.

New <- FindVariableGenes(object = New, mean.function = ExpMean, dispersion.function = LogVMR, 
    x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5)

# Found 1526 variable genes
length(x = New@var.genes)

#Scaling the data and removing unwanted sources of variation
#Your single cell dataset likely contains ‘uninteresting’ sources of variation. This could include not only technical noise, but batch effects, or even biological sources of variation (cell cycle stage). As suggested in Buettner et al, NBT, 2015, regressing these signals out of the analysis can improve downstream dimensionality reduction and clustering. To mitigate the effect of these signals, Seurat constructs linear models to predict gene expression based on user-defined variables. The scaled z-scored residuals of these models are stored in the scale.data slot, and are used for dimensionality reduction and clustering.

#We can regress out cell-cell variation in gene expression driven by batch (if applicable), cell alignment rate (as provided by Drop-seq tools for Drop-seq data), the number of detected molecules, and mitochondrial gene expression. For cycling cells, we can also learn a ‘cell-cycle’ score (see example [HERE]) and regress this out as well. In this simple example here for post-mitotic blood cells, we regress on the number of detected molecules per cell as well as the percentage mitochondrial gene content.

# Seurat v2.0 implements this regression as part of the data scaling process. Therefore, the RegressOut function has been deprecated, and replaced with the vars.to.regress argument in ScaleData.
New <- ScaleData(object = New, vars.to.regress = c("nUMI", "percent.mito"))
# Perform a linear dimension reduction on the scaled data
New <- RunPCA(object = New, pc.genes = New@var.genes, do.print = TRUE, pcs.print = 1:5, 
    genes.print = 5)

#Examine and visualize PCA results a few different ways
PrintPCA(object = New, pcs.print = 1:5, genes.print = 5, use.full = FALSE)
VizPCA(object = New, pcs.use = 1:2)
PCAPlot(object = New, dim.1 = 1, dim.2 = 2)
PCHeatmap(object = New, pc.use = 1:12, cells.use = 500, do.balanced = TRUE, label.columns = FALSE, use.full = FALSE)
PCElbowPlot(object = New)

# Using the dimensions 1 to 10 to discover clusters with a resolution of 0.6. 
# Increasing this resolution up to 1.2 will increase the number of clusters discovered
# So this might be something I should explore later.
New <- FindClusters(object = New, reduction.type = "pca", dims.use = 1:10, 
    resolution = 0.6, print.output = 0, save.SNN = TRUE)
# Now run the Tsne
New <- RunTSNE(object = New, dims.use = 1:10, do.fast = TRUE)
# Save the Metadata
MetaData_combined = as.data.frame(New@meta.data)
# Create a new column that depicts the sequencing batch
MetaData_combined$Batch = ifelse(MetaData_combined$CellType == 'Young','Batch1','Batch2')
# Lets also track the cells that are relatively high for Jun
# so we can regress them out later
MetaData_combined$Jun_Status = ifelse(MetaData_combined$res.0.6 == 0,'High','Low')
# Plot the Tsne
TSNEPlot(object = New,do.label=TRUE)
write.csv(MetaData_combined,'MetaData_combined.csv')
# Lets switch the id to CellType so we can cluster by young or old
expressionTsne_2 <- SetAllIdent(object = New, id = "CellType")
# Plot
TSNEPlot(object = expressionTsne_2)

# find all markers of cluster 0
cluster0.markers <- FindMarkers(object = New, ident.1 = 0, min.pct = 0.25)
print(x = head(x = cluster0.markers, n = 10))
# find all markers of cluster 1
cluster1.markers <- FindMarkers(object = New, ident.1 = 1, min.pct = 0.25)
print(x = head(x = cluster1.markers, n = 10))
# find all markers of cluster 2
cluster2.markers <- FindMarkers(object = New, ident.1 = 2, min.pct = 0.25)
print(x = head(x = cluster2.markers, n = 10))
# find all markers of cluster 3
cluster3.markers <- FindMarkers(object = New, ident.1 = 3, min.pct = 0.25)
print(x = head(x = cluster3.markers, n = 10))
cluster4.markers <- FindMarkers(object = New, ident.1 = 4, min.pct = 0.25)
print(x = head(x = cluster4.markers, n = 10))
cluster5.markers <- FindMarkers(object = New, ident.1 = 5, min.pct = 0.25)
print(x = head(x = cluster5.markers, n = 10))
cluster6.markers <- FindMarkers(object = New, ident.1 = 6, min.pct = 0.25)
print(x = head(x = cluster6.markers, n = 10))
cluster7.markers <- FindMarkers(object = New, ident.1 = 7, min.pct = 0.25)
print(x = head(x = cluster7.markers, n = 10))
cluster8.markers <- FindMarkers(object = New, ident.1 = 8, min.pct = 0.25)
print(x = head(x = cluster8.markers, n = 10))
cluster9.markers <- FindMarkers(object = New, ident.1 = 9, min.pct = 0.25)
print(x = head(x = cluster9.markers, n = 10))
cluster10.markers <- FindMarkers(object = New, ident.1 = 10, min.pct = 0.25)
print(x = head(x = cluster10.markers, n = 10))

# find markers for every cluster compared to all remaining cells, report
# only the positive ones
New.markers <- FindAllMarkers(object = New, only.pos = TRUE, min.pct = 0.25, 
    thresh.use = 0.25)
New.markers %>% group_by(cluster) %>% top_n(10, avg_logFC)

# find markers for every cluster compared to all remaining cells, report
# only the positive ones
New.markers <- FindAllMarkers(object = New, only.pos = TRUE, min.pct = 0.25, 
    thresh.use = 0.25)
New.markers %>% group_by(cluster) %>% top_n(2, avg_logFC)

# Top markers plots
# Cluster 0
FeaturePlot(object = New, features.plot = c("Hspa1a","Aqp1","Jun","Junb","Cdkn1a","Egr1"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 1
FeaturePlot(object = New, features.plot = c("Fabp4","Gpihbp1","Aqp1","Timp4","Rgcc","C1qtnf9"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 2
FeaturePlot(object = New, features.plot = c("Cxcl12","Aqp7","Mgll","Rbp7","Btnl9","Slc26a10"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 3
FeaturePlot(object = New, features.plot = c("Fbln5","Stmn2","Glul","Alpl","Rbp7","Alox12"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 4
FeaturePlot(object = New, features.plot = c("Ifit1","Ifit3","Isg15","Ifit2","Rsad2","Rtp4"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 5
FeaturePlot(object = New, features.plot = c("Cfh","Dcn","Mgp","Cpe","Apoe","Cytl1"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 6
FeaturePlot(object = New, features.plot = c("Ift122","Fscn1","Mycn","Tubb5","Hmgb2","Tmsb10"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 7
FeaturePlot(object = New, features.plot = c("Prss23","Calcrl","Vwf","Cd9","Vcam1","Fmo2"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 8
FeaturePlot(object = New, features.plot = c("Mmrn1","Ccl21a","Pard6g","Fgl2","Lcn2","Lyve1"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 9
FeaturePlot(object = New, features.plot = c("Rgs5","Acta2","Tpm2","Myl9","Tagln","Myh11"), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 10
FeaturePlot(object = New, features.plot = c("Cd74","Rac2","Cd52","H2-Ab1","Cd79a","H2-Aa"), cols.use = c("grey", "blue"),reduction.use = "tsne")


# Violin Plots for cluster markers
VlnPlot(object = New, features.plot = c("Hspa1a","Aqp1","Jun","Junb","Cdkn1a","Egr1"))
VlnPlot(object = New, features.plot = c("Fabp4","Gpihbp1","Aqp1","Timp4","Rgcc","C1qtnf9"))
VlnPlot(object = New, features.plot = c("Cxcl12","Aqp7","Mgll","Rbp7","Btnl9","Slc26a10"))
VlnPlot(object = New, features.plot = c("Fbln5","Stmn2","Glul","Alpl","Rbp7","Alox12"))
VlnPlot(object = New, features.plot = c("Ifit1","Ifit3","Isg15","Ifit2","Rsad2","Rtp4"))
VlnPlot(object = New, features.plot = c("Cfh","Dcn","Mgp","Cpe","Apoe","Cytl1"))
VlnPlot(object = New, features.plot = c("Ift122","Fscn1","Mycn","Tubb5","Hmgb2","Tmsb10"))
VlnPlot(object = New, features.plot = c("Prss23","Calcrl","Vwf","Cd9","Vcam1","Fmo2"))
VlnPlot(object = New, features.plot = c("Mmrn1","Ccl21a","Pard6g","Fgl2","Lcn2","Lyve1"))
VlnPlot(object = New, features.plot = c("Rgs5","Acta2","Tpm2","Myl9","Tagln","Myh11"))
VlnPlot(object = New,features.plot = c("Cd74","Rac2","Cd52","H2-Ab1","Cd79a","H2-Aa"))


# Plot heatmap with the top 10 genes for each cluster
top10 <- New.markers %>% group_by(cluster) %>% top_n(10, avg_logFC)
# setting slim.col.label to TRUE will print just the cluster IDS instead of
# every cell name
DoHeatmap(object = New, genes.use = top10$gene, slim.col.label = TRUE, remove.key = TRUE)
```























# http://satijalab.org/seurat/interaction_vignette.html

# Create a Seurat object
```{r}
# First make the expression data as a sparse data frame to speed up computation. 
# Our combined data is not numeric, so convert the data frame to numeric
Combined1 = data.matrix(Combined)
# Then convert to a sparse matrix
expression.data <- Matrix(Combined1, sparse = T)
# Sanity check
expression.data[1:3,1:3]
# Now create a seurat object.
# Keep all genes expressed in >= 3 cells (~0.1% of the data). Note we can also keep all cells with at
# least 200 detected genes by specifying min.genes = 200. Try this at some point to see how that changes the clustering
expressionObject <- CreateSeuratObject(raw.data = expression.data, min.cells = 3)
# Add the metadata to the  seurat object created
expressionObject_1 <- AddMetaData(expressionObject, metadata = AnnotationFile2)
# You can view the contents of the seurat obj by using the @ function eg
# To view the meta.data slot in the Seurat Object
head(expressionObject_1@meta.data)

# Filter out cells with low genes detected. I used 500 as the lowest threshold for no apparent reason. I need to come
# back and look at the nGene column to make a more informed decision on the threshold. The high threshold was set as inf
# I didnt filter on uMI though. Maybe I shoud?????
expressionFilteredObj <- FilterCells(expressionObject_1, subset.names = "nGene", low.thresholds = 500,  high.thresholds = Inf)
# Normalize data set 
expressionNormalized <- NormalizeData(expressionFilteredObj)
# Keep only variable genes that will be informative for clustering.
# I need to understand the parameter x.low.cutoff. I just used the default setting @ 0.1
expressionVariable <- FindVariableGenes(expressionNormalized, x.low.cutoff = 0.1)
# Scale the data
expressionScaled <- ScaleData(expressionVariable, genes.use = expressionVariable@var.genes, model.use = "negbinom")

# Save current expression data as csv file for independent analysis
# Saving the normalized data
# First re convert back to dense matrix
NormalizedData = as.matrix(expressionScaled@data)
# Sanity check
NormalizedData[1:3,1:3]
dim(NormalizedData)
# Save as csv
write.csv(NormalizedData,'Combined_Normalized_Seurat.csv')
# Now do the same process but this time for ScaledData
ScaledData = as.matrix(expressionScaled@scale.data)
# Sanity check
ScaledData[1:3,1:3]
dim(ScaledData)
# Save as csv
write.csv(ScaledData,'Combined_Normalized_Scaled_Seurat.csv')


# Linear Dimensionality Reduction using PCA
# Now reduce the dimensions of the scaled features by running the PCA and saving 30 dimensions
# So all the features (~27k genes) are collapsed into 30 features
expressionPCA <- RunPCA(expressionScaled, pcs.compute = 30, weight.by.var = FALSE)

# Use the dimensions generated by PCA to create the tsne but we dont use all the dims
# we just use first 19 dimensions
expressionTsne <- RunTSNE(expressionPCA, dims.use = 1:19, do.fast = T)

# Note that we dont have to use all 19. We can use some permuation technique to figure out which
# PC components are significant. Seurat has a function that does that. So I should try and use
# that to determine what PC components are significant. 
# So now lets find the clusters 
expressionClusters <- FindClusters(expressionTsne, reduction.type = "pca", dims.use = 1:19, save.SNN = T)
# color by cluster ID, annotated cluster from the manuscript, or batch
# Can switch the identity class using SetAllIdent if desired
TSNEPlot(expressionClusters, do.label = T)
# Lets switch the id to CellType in the meta data so we can cluster by either
# young or oold status
expressionTsne_2 <- SetAllIdent(object = expressionTsne, id = "CellType")
# Plot
TSNEPlot(expressionTsne_2)


# The analysis did not account for nGene as the main driver of the clusters.
# I decided to run an alternative analysis where I account for that
```

# Use an alternative seurat work flow
```{r}
New <- CreateSeuratObject(raw.data = expression.data, min.cells = 3, min.genes = 200, 
    project = "10X_old")

mito.genes <- grep(pattern = "^MT-", x = rownames(x = New@data), value = TRUE)
percent.mito <- Matrix::colSums(New@raw.data[mito.genes, ])/Matrix::colSums(New@raw.data)
# Add percent.mito to the metadata
New <- AddMetaData(object = New, metadata = percent.mito, col.name = "percent.mito")
# Also add the cell annotation as part of the metadata
New1 = AddMetaData(object=New,metadata = AnnotationFile2)
# This threw up a warning. Understand that warning. The plot is also kinda different from the plot from the tutorial;
# The warning is that all cells have the same value of feature
VlnPlot(object = New1, features.plot = c("nGene", "nUMI", "percent.mito"), nCol = 3)

# We filter out cells that have unique gene counts over 2,500 or less than
# 200 Note that low.thresholds and high.thresholds are used to define a
# 'gate' -Inf and Inf should be used if you don't want a lower or upper
# threshold.
New <- FilterCells(object = New1, subset.names = c("nGene", "percent.mito"), 
    low.thresholds = c(200, -Inf), high.thresholds = c(2500, 0.05))

# Normalizing the data
# After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.

New <- NormalizeData(object = New, normalization.method = "LogNormalize", 
    scale.factor = 10000)

# Detection of variable genes across the single cells
# Seurat calculates highly variable genes and focuses on these for downstream analysis. FindVariableGenes calculates the average expression and dispersion for each gene, places these genes into bins, and then calculates a z-score for dispersion within each bin. This helps control for the relationship between variability and average expression. This function is unchanged from (Macosko et al.), but new methods for variable gene expression identification are coming soon. We suggest that users set these parameters to mark visual outliers on the dispersion plot, but the exact parameter settings may vary based on the data type, heterogeneity in the sample, and normalization strategy. The parameters here identify ~2,000 variable genes, and represent typical parameter settings for UMI data that is normalized to a total of 1e4 molecules.

New <- FindVariableGenes(object = New, mean.function = ExpMean, dispersion.function = LogVMR, 
    x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5)

# Found 3106 variable genes
length(x = New@var.genes)

#Scaling the data and removing unwanted sources of variation
#Your single cell dataset likely contains ‘uninteresting’ sources of variation. This could include not only technical noise, but batch effects, or even biological sources of variation (cell cycle stage). As suggested in Buettner et al, NBT, 2015, regressing these signals out of the analysis can improve downstream dimensionality reduction and clustering. To mitigate the effect of these signals, Seurat constructs linear models to predict gene expression based on user-defined variables. The scaled z-scored residuals of these models are stored in the scale.data slot, and are used for dimensionality reduction and clustering.

#We can regress out cell-cell variation in gene expression driven by batch (if applicable), cell alignment rate (as provided by Drop-seq tools for Drop-seq data), the number of detected molecules, and mitochondrial gene expression. For cycling cells, we can also learn a ‘cell-cycle’ score (see example [HERE]) and regress this out as well. In this simple example here for post-mitotic blood cells, we regress on the number of detected molecules per cell as well as the percentage mitochondrial gene content.

# Seurat v2.0 implements this regression as part of the data scaling process. Therefore, the RegressOut function has been deprecated, and replaced with the vars.to.regress argument in ScaleData.
New <- ScaleData(object = New, vars.to.regress = c("nUMI", "percent.mito"))
# Perform a linear dimension reduction on the scaled data
New <- RunPCA(object = New, pc.genes = New@var.genes, do.print = TRUE, pcs.print = 1:5, 
    genes.print = 5)

#Examine and visualize PCA results a few different ways
PrintPCA(object = New, pcs.print = 1:5, genes.print = 5, use.full = FALSE)
VizPCA(object = New, pcs.use = 1:2)
PCAPlot(object = New, dim.1 = 1, dim.2 = 2)
PCHeatmap(object = New, pc.use = 1:12, cells.use = 500, do.balanced = TRUE, label.columns = FALSE, use.full = FALSE)
PCElbowPlot(object = New)

# Using the dimensions 1 to 10 to discover clusters with a resolution of 0.6. 
# Increasing this resolution up to 1.2 will increase the number of clusters discovered
# So this might be something I should explore later.
New <- FindClusters(object = New, reduction.type = "pca", dims.use = 1:10, 
    resolution = 0.6, print.output = 0, save.SNN = TRUE)
# Now run the Tsne
New <- RunTSNE(object = New, dims.use = 1:10, do.fast = TRUE)
# Plot the Tsne
TSNEPlot(object = New,do.label=TRUE)


# Lets switch the id to CellType so we can cluster by young or old
expressionTsne_2 <- SetAllIdent(object = New, id = "CellType")
# Plot
TSNEPlot(object = expressionTsne_2)

# Add two new columns to the metadata which will group cells by age_cluster or cluster_age
New@meta.data$Cluster_Age = paste(New@meta.data$CellType,New@meta.data$res.0.6,sep='_')
New@meta.data$Age_Cluster = paste(New@meta.data$res.0.6,New@meta.data$CellType,sep='_')

# Save the metadata of this clustering analysis 
MetaData_Combined = data.frame(New@meta.data)
# Since I combined data of the Old and the Young and these were done in separate batches,
# I also added a new column in the metadata that codes Young as batch_1 and Old as batch_2
# There seem to be an age-dependent effect in the clustering. An alternative explanation is that
# this is a batch effect stemming from the fact that the two time points were assayed independently
# We probabaly should normalize for batch effect
MetaData_Combined$Batch = ifelse(MetaData_Combined$CellType == 'Young','Batch_1','Batch_2')
write.csv(MetaData_Combined,'MetaData_Combined.csv')

# find all markers of cluster 0
cluster0.markers <- FindMarkers(object = New, ident.1 = 0, min.pct = 0.25)
print(x = head(x = cluster0.markers, n = 10))
# find all markers of cluster 1
cluster1.markers <- FindMarkers(object = New, ident.1 = 1, min.pct = 0.25)
print(x = head(x = cluster1.markers, n = 10))
# find all markers of cluster 2
cluster2.markers <- FindMarkers(object = New, ident.1 = 2, min.pct = 0.25)
print(x = head(x = cluster2.markers, n = 10))
# find all markers of cluster 3
cluster3.markers <- FindMarkers(object = New, ident.1 = 3, min.pct = 0.25)
print(x = head(x = cluster3.markers, n = 10))
cluster4.markers <- FindMarkers(object = New, ident.1 = 4, min.pct = 0.25)
print(x = head(x = cluster4.markers, n = 10))
cluster5.markers <- FindMarkers(object = New, ident.1 = 5, min.pct = 0.25)
print(x = head(x = cluster5.markers, n = 10))
cluster6.markers <- FindMarkers(object = New, ident.1 = 6, min.pct = 0.25)
print(x = head(x = cluster6.markers, n = 10))
cluster7.markers <- FindMarkers(object = New, ident.1 = 7, min.pct = 0.25)
print(x = head(x = cluster7.markers, n = 10))

# find markers for every cluster compared to all remaining cells, report
# only the positive ones
New.markers <- FindAllMarkers(object = New, only.pos = TRUE, min.pct = 0.25, 
    thresh.use = 0.25)
New.markers %>% group_by(cluster) %>% top_n(10, avg_logFC)

# find markers for every cluster compared to all remaining cells, report
# only the positive ones
New.markers <- FindAllMarkers(object = New, only.pos = TRUE, min.pct = 0.25, 
    thresh.use = 0.25)
New.markers %>% group_by(cluster) %>% top_n(2, avg_logFC)

# Top markers plots
# Cluster 0
FeaturePlot(object = New, features.plot = c("Igf1r", "Spock2",'Adgrf5','Pdgfb','Slc39a10','Slc7a1'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 1
FeaturePlot(object = New, features.plot = c("Junb", "Jun",'Btg2','Fos','Atf3','Ier2'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 2
FeaturePlot(object = New, features.plot = c("Itm2a", "Nedd8",'Anp32a','Cbx3','Car4','Apoe'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 3
FeaturePlot(object = New, features.plot = c("Gkn3", "Glul",'Stmn2','Vegfc','Alpl','Clu'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 4
FeaturePlot(object = New, features.plot = c("Cd14", "Lcn2",'Lrg1','Vcam1','Ptgs2','Ackr1'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 5
FeaturePlot(object = New, features.plot = c("Vtn", "Atp1a2",'Rgs4','Kcnj8','Myl9','Pdgfrb'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 6
FeaturePlot(object = New, features.plot = c("Plvap", "Nrp1",'Car8','Esm1','Plpp3','Igfbp3'), cols.use = c("grey", "blue"),reduction.use = "tsne")
# Cluster 7
FeaturePlot(object = New, features.plot = c("Cd52", "Cd74",'Cd79a','Cd79b','Plac8','Lyz2'), cols.use = c("grey", "blue"),reduction.use = "tsne")


# Feature Plots for known markers
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5','Efnb2','Dll4','Ephb4','Mfsd2a'), cols.use = c("grey", "blue"),reduction.use = "tsne")
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5',"Vcam1",'Icam1','Lrg1','Cd74'), cols.use = c("grey", "blue"),reduction.use = "tsne")
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5','Pvlap','Vwf','Ptprc','Cd14'), cols.use = c("grey", "blue"),reduction.use = "tsne")

# Violin Plots for cluster markers
VlnPlot(object = New, features.plot = c("Igf1r", "Spock2",'Adgrf5','Pdgfb','Slc39a10','Slc7a1'))
VlnPlot(object = New, features.plot = c("Junb", "Jun",'Btg2','Fos','Atf3','Ier2'))
VlnPlot(object = New, features.plot = c("Itm2a", "Nedd8",'Anp32a','Cbx3','Car4','Apoe'))
VlnPlot(object = New, features.plot = c("Gkn3", "Glul",'Stmn2','Vegfc','Alpl','Clu'))
VlnPlot(object = New, features.plot = c("Cd14", "Lcn2",'Lrg1','Vcam1','Ptgs2','Ackr1'))
VlnPlot(object = New, features.plot = c("Vtn", "Atp1a2",'Rgs4','Kcnj8','Myl9','Pdgfrb'))
VlnPlot(object = New, features.plot = c("Plvap", "Plpp1",'Car8','Esm1','Plpp3','Igfbp3'))
VlnPlot(object = New, features.plot = c("Cd52", "Cd74",'Cd79a','Cd79b','Plac8','Lyz2'))


# Plot heatmap with the top 10 genes for each cluster
top10 <- New.markers %>% group_by(cluster) %>% top_n(10, avg_logFC)
# setting slim.col.label to TRUE will print just the cluster IDS instead of
# every cell name
DoHeatmap(object = New, genes.use = top10$gene, slim.col.label = TRUE, remove.key = TRUE)

#FeaturePlot(object = New, features.plot = c("Junb", "Jun",'Jund','Fos','Cdkn1a','Ier2'), cols.use = c("grey", "blue"),reduction.use = "tsne")
#FeaturePlot(object = New, features.plot = c("Nfib",'Igf1r','Mcf2l','Kdr','Cxcl12','Hmcn1'), cols.use = c("grey", "blue"),reduction.use = "tsne")
#FeaturePlot(object = old, features.plot = c('Stmn2','Gkn3','Tm4sf1','Lypd1','Mgp','Clu'), cols.use = c("grey", "blue"),reduction.use = "tsne")
#FeaturePlot(object = New, features.plot = c('Fth1','Lcn2','Lrg1','Vcam1','Icam1','Ptgs2'), cols.use = c("grey", "blue"),reduction.use = "tsne")
#FeaturePlot(object = old, features.plot = c('Myl9','Atp1a2','Vtn','Cald1','Acta2','Rgs4'), cols.use = c("grey", "blue"),reduction.use = "tsne")
#FeaturePlot(object = old, features.plot = c("Junb", "Jun",'Jund','Fos','Adm','Btg2'), cols.use = c("grey", "blue"),reduction.use = "tsne")


# Cluster 0,1 ,2,3 and 4 looks like pure endothelial cells. 4 looks to be well
# clustered out. So I wanted to grab Clusters 0,1,2 and 3 and then recluster them
# to see if the clusters will be more distinct.
# This will display the number of cells in each group
# For group 0,1,2 and 3 the number of cells are 1246
table(New@meta.data$res.0.6)
# Now grab the Cell ids of Cluster 0,1,2,3
Group0_1_2_3 = c(0,1,2,3)
Cell_ids = WhichCells(object=New,ident=Group0_1_2_3)
# Get Cell_ids of cluster 5
Cell_ids_cluster5 = WhichCells(object=New,ident=5)
# Sanity check
length(Cell_ids)
length(Cell_ids_cluster5)
# This checks out as the total number of cell ids is 1246.

# Create a seurat object with only cells that fall in cluster 0,1,2 and 3
Group.subset <- SubsetData(object = New, ident.use = Group0_1_2_3)
# Create a seurat object with only cells of cluster 5
Group5 = SubsetData(object = New, ident.use = 5)
# Now get the expression data as well as the corresponding annotation
# of the identified subset from the seurat object.
# expression data
Group_data = as.matrix(Group.subset@data)
Group_data5 = as.matrix(Group5@data)
# Also get the raw data. I figured getting the raw data will make it easier to re run 
# seurat on groups of cell clusters in this case cluster 5
Group_data5_raw_data = as.matrix(Group5@raw.data)
# However, I quickly realized that the raw data is actaully the data for the entire cells
# and not just group 5 as we had in Group_data5 i.e 
Group_data5_raw_data[1:3,1:3]
Group_data5[1:3,1:3]
# I have the Cell ids for group 5 , so I will just use that cell id's and subset the group 5 raw data from the entire raw data. First make the data a data frame
Group_data5_raw_data_dataframe = as.data.frame(Group_data5_raw_data)
# Now use the group 5 cell id's to subset the group 5 raw data
Group5_filtered_raw_data=Group_data5_raw_data_dataframe[Cell_ids_cluster5]

# Corresponding Annotation
Group_annotation = as.data.frame(Group.subset@meta.data$CellType)
Group_annotation5 = as.data.frame(Group5@meta.data$CellType)
# Get the row names of the meta data
row_names = row.names(Group.subset@meta.data)
row_names5 = row.names(Group5@meta.data)
# Attach the row names as a column in the Annotation file
Group_annotation1 = cbind(Group_annotation,'CellNames'= row_names)
Group_annotation5_1 = cbind(Group_annotation5,'CellNames'= row_names5)
# Make this new column as row name
rownames(Group_annotation1) = Group_annotation1$CellNames
rownames(Group_annotation5_1) = Group_annotation5_1$CellNames
# Now drop the redundant CellNames column
Group_annotation2 = Group_annotation1 %>% select (-CellNames)
Group_annotation5_2 = Group_annotation5_1 %>% select (-CellNames)
# Rename the column name to just CellType
Group_annotation3=rename(Group_annotation2,CellType = 'Group.subset@meta.data$CellType')
Group_annotation5_3=rename(Group_annotation5_2,CellType = 'Group5@meta.data$CellType')
# So we have the annotation data and the expression data matrix. The column names
# of the expression data matrix must match the row names of the annotation file
# Test that. This should return True
all(row.names(Group_annotation3)==colnames(Group_data))
all(row.names(Group_annotation5_3)==colnames(Group5_filtered_raw_data))



# Save as a csv file with the purpose of re-running the analysis with
# clusters 0,1,2 and 3 raw data. For group 5 I saved both the normalized data as
# well as the raw data. But I will be using the raw data to re run seurat on the 
# group 5 cluster as well as other down stream analysis like differential gene
# analysis between young and old group 5 cluster
write.csv(Group_data,"Combined_0_3_clusters.csv")
write.csv(Group_data5,"Combined_5_clusters.csv")
write.csv(Group5_filtered_raw_data,'Group5Rawdata.csv')
# Save annotation
write.csv(Group_annotation3,'GroupAnnotation.csv')
write.csv(Group_annotation5_3,'GroupAnnotation5_clusters.csv')

# Now do the analysis on these clusters in an rmd file named
# Combined_Cluster0_4_Seurat



















VlnPlot(object = New, features.plot = c("Junb", "Jun",'Jund','Fos','Ubb','Rpl41'))
VlnPlot(object = New, features.plot = c("Junb",'Rpl41','Igf1r','Ubb','Fos','Slco1c1'))
VlnPlot(object = New, features.plot = c('Lrg1','Ackr1','Ch25h','Lcn2','Cfh','Vcam1'))
VlnPlot(object = New, features.plot = c('Esm1','Ces2e','Fam167b','Car8','Col15a1','Plvap'))
top10 <- New.markers %>% group_by(cluster) %>% top_n(10, avg_logFC)
# setting slim.col.label to TRUE will print just the cluster IDS instead of
# every cell name
DoHeatmap(object = New, genes.use = top10$gene, slim.col.label = TRUE, remove.key = TRUE)

# Feature Plots
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5','Efnb2','Dll4','Ephb4','Mfsd2a'), cols.use = c("grey", "blue"),reduction.use = "tsne")
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5',"Vcam1",'Icam1','Lrg1','Cd74'), cols.use = c("grey", "blue"),reduction.use = "tsne")
FeaturePlot(object = New, features.plot = c("Pecam1",'Cldn5','Pvlap','Vwf','Ptprc','Cd14'), cols.use = c("grey", "blue"),reduction.use = "tsne")
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
